http://cygx.mydns.jp/blog/?arti=559

リスト
1. IMU/カメラ画像/Lidar(Depth)
2. 単眼カメラからの密な3次元復元（Dense 3D Reconstruction from monocular image, real-time SfM, Monocular SLAM）

1.
VIRAL (visual-inertial-ranging-lidar) SLAM, sensor fusion
LIC-Fusion: LiDAR-Inertial-Camera Odometry
“Laser–visual–inertial odometry and mapping
with high robustness and low drift,” (J. Zhang and S. Singh)


2.Monocular SLAM
vslam流れ->https://noshumi.blogspot.com/2017/05/visual-slam-1visual-slam.html

・DTAM(Dense Tracking and Motion).2011
約10年前 実装がない(OpenDTAMはGithub上にある)　精度良
loop close検出持たない->机の上程度のみ，広範囲のSLAMは不可能
PTAM(2007)は特徴点を抽出する方法(indirect)

動画
https://www.youtube.com/watch?v=Df9WhgibCQA&ab_channel=imperialrobotvision
paper
https://www.doc.ic.ac.uk/~ajd/Publications/newcombe_etal_iccv2011.pdf
GPU上で動く
https://noshumi.blogspot.com/2017/08/lsd-slam.html


・LSD-SLAM(Large Scale).2014
デモ動画でARの車走らせてるやつ
CPUでも動く，directな手法，denseではなくsemi-dense
DTAMと異なりループ検出あるので，机の上だけじゃなくlarge scaleに適用可能
公式ページ->https://vision.in.tum.de/research/vslam/lsdslam


・Dynamic Fusion.2015
動いている人もリアルタイム復元
http://www.youtube.com/watch?v=i1eZekcc_lM

・DSO(Direct Sparse Odometry).2017
https://www.slideshare.net/MasayaKaneko/direct-sparse-odometry


・Yさん実装
https://www.youtube.com/watch?v=TZ1eToXQwN0&ab_channel=MobileRoboticsResearchTeam-MR2T-MobileRoboticsResearchTeam-MR2T-

・課題
精度・正則化（外れ値）特徴量の対応付けに失敗、スケール不定(scale uncertainty)->単眼カメラによるVisual SLAMの原理と3次元再構成の実装例
静止物体ではなく動物体に対応可
テクスチャのない(textureless)部分はどう特徴量える？
ノイズ（人の手が入る）の除去

cube-slam 深層学習（3d bbox）を上手く取り入れた手法


・用語（https://noshumi.blogspot.com/2017/08/lsd-slam.html）
自己位置推定(tracking)-> 6d camera motion(pose)
パッチ->４pixel*4pixelの四角形
SO(3)->special orthogonal 特殊直行群(slambook-en.pdf(https://github.com/gaoxiang12/slambook-en) page50 式(3.7)を満たすグループの行列のこと)，3次元回転
SE(3)->特殊ユークリッド群，3次元剛体変換(3次元回転+並進)
a×b = a^b a^は歪対称行列（定義：A^t(Aの転置)=-A）, ベクトルの外積を行列で表したい．^([]x)はオペレータ(slambook-en.pdf page48 式(3.3)より)
ノルム->距離の最小化（https://library.naist.jp/mylimedio/dllimedio/showpdf2.cgi/DLPDFR008313_P1-60）
測光誤差，逆投影関数Π^-1(2D->3D)->
14pageめ/58(https://www.slideshare.net/MasayaKaneko/direct-sparse-odometry)


https://daily-tech.hatenablog.com/entry/2016/04/29/145737
現在のキーフレームを Ki = (Ii,Di,Vi) とすると，新しいイメージ Ij の相対 3次元ポーズ ξji∈se(3) は，下記の分散値で正規化された測光誤差関数を最小化することによって求められる
（カメラの相対姿勢ξを求めるトラッキングは，測光誤差関数を最小化することによって求められる）